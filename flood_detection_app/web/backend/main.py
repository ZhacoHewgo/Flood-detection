"""
FastAPIåç«¯æœåŠ¡
FastAPI Backend Service for Flood Detection Web Application
"""

import os
import io
import base64
import time
import asyncio
from typing import List, Dict, Any, Optional
from fastapi import FastAPI, UploadFile, File, HTTPException, Form, Depends, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
import numpy as np
from PIL import Image
import cv2
from concurrent.futures import ThreadPoolExecutor
import threading
from functools import lru_cache
import gc

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
from ...core import (
    ModelManager, ImageProcessor, FloodAnalyzer, VisualizationEngine,
    config_manager
)
from ...core.exceptions import FloodDetectionError, ModelLoadError, InferenceError
from ...core.data_models import Statistics, AnalysisResult


# Pydanticæ¨¡å‹å®šä¹‰
class VehicleResult(BaseModel):
    id: int
    bbox: List[float]  # [x1, y1, x2, y2]
    confidence: float
    flood_level: str
    overlap_ratio: float


class AnalysisResponse(BaseModel):
    success: bool
    message: str
    vehicles: List[VehicleResult]
    statistics: Dict[str, Any]
    processing_time: float
    result_image_base64: str
    water_coverage_percentage: float


class ModelsResponse(BaseModel):
    vehicle_models: List[str]
    water_models: List[str]


class HealthResponse(BaseModel):
    status: str
    timestamp: float
    models_loaded: bool
    version: str


class ErrorResponse(BaseModel):
    success: bool
    error: str
    error_code: str


# åˆ›å»ºFastAPIåº”ç”¨ - æ€§èƒ½ä¼˜åŒ–ç‰ˆæœ¬
app = FastAPI(
    title="ç§¯æ°´è½¦è¾†æ£€æµ‹API",
    description="åŸºäºæ·±åº¦å­¦ä¹ çš„ç§¯æ°´è½¦è¾†æ£€æµ‹åˆ†ææœåŠ¡ - æ€§èƒ½ä¼˜åŒ–ç‰ˆ",
    version="1.0.0"
)

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿäº§ç¯å¢ƒä¸­åº”è¯¥é™åˆ¶å…·ä½“åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€å˜é‡
model_manager = None
image_processor = None
flood_analyzer = None
viz_engine = None
models_loaded = False

# æ€§èƒ½ä¼˜åŒ–è®¾ç½®
executor = ThreadPoolExecutor(max_workers=4)  # ç”¨äºCPUå¯†é›†å‹ä»»åŠ¡
analysis_lock = threading.Lock()  # é˜²æ­¢å¹¶å‘åˆ†æå†²çª
request_cache = {}  # ç®€å•çš„è¯·æ±‚ç¼“å­˜
cache_lock = threading.Lock()


@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨äº‹ä»¶"""
    global model_manager, image_processor, flood_analyzer, viz_engine, models_loaded
    
    try:
        print("æ­£åœ¨åˆå§‹åŒ–åç«¯æœåŠ¡...")
        
        # åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
        model_manager = ModelManager()
        image_processor = ImageProcessor()
        flood_analyzer = FloodAnalyzer()
        viz_engine = VisualizationEngine()
        
        # åŠ è½½æ¨¡å‹
        print("æ­£åœ¨åŠ è½½æ·±åº¦å­¦ä¹ æ¨¡å‹...")
        success = model_manager.load_models()
        
        if success:
            models_loaded = True
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        else:
            print("âš ï¸ éƒ¨åˆ†æ¨¡å‹åŠ è½½å¤±è´¥")
            
        print("ğŸš€ åç«¯æœåŠ¡å¯åŠ¨å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ åç«¯æœåŠ¡å¯åŠ¨å¤±è´¥: {e}")
        models_loaded = False


@app.get("/", response_model=Dict[str, str])
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "message": "ç§¯æ°´è½¦è¾†æ£€æµ‹APIæœåŠ¡",
        "version": "1.0.0",
        "docs": "/docs"
    }


@app.get("/api/health", response_model=HealthResponse)
async def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return HealthResponse(
        status="healthy" if models_loaded else "degraded",
        timestamp=time.time(),
        models_loaded=models_loaded,
        version="1.0.0"
    )


@app.get("/api/models", response_model=ModelsResponse)
async def get_available_models():
    """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
    try:
        if not models_loaded or model_manager is None:
            raise HTTPException(
                status_code=503,
                detail="æ¨¡å‹æœªåŠ è½½ï¼ŒæœåŠ¡ä¸å¯ç”¨"
            )
        
        available_models = model_manager.get_available_models()
        
        return ModelsResponse(
            vehicle_models=available_models.get('vehicle_models', []),
            water_models=available_models.get('water_models', [])
        )
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {str(e)}"
        )


@app.post("/api/analyze", response_model=AnalysisResponse)
async def analyze_image(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    vehicle_model: str = Form("YOLOv11 Car Detection"),
    water_model: str = Form("DeepLabV3 Water Segmentation")
):
    """å›¾åƒåˆ†ææ¥å£ - æ€§èƒ½ä¼˜åŒ–ç‰ˆæœ¬"""
    try:
        # æ£€æŸ¥æœåŠ¡çŠ¶æ€
        if not models_loaded or model_manager is None:
            raise HTTPException(
                status_code=503,
                detail="æ¨¡å‹æœªåŠ è½½ï¼ŒæœåŠ¡ä¸å¯ç”¨"
            )
        
        # éªŒè¯æ–‡ä»¶ç±»å‹å’Œå¤§å°
        if not file.content_type.startswith('image/'):
            raise HTTPException(
                status_code=400,
                detail="æ–‡ä»¶ç±»å‹é”™è¯¯ï¼Œè¯·ä¸Šä¼ å›¾åƒæ–‡ä»¶"
            )
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆé™åˆ¶ä¸º10MBï¼‰
        if file.size and file.size > 10 * 1024 * 1024:
            raise HTTPException(
                status_code=400,
                detail="æ–‡ä»¶è¿‡å¤§ï¼Œè¯·ä¸Šä¼ å°äº10MBçš„å›¾åƒ"
            )
        
        start_time = time.time()
        
        # å¼‚æ­¥è¯»å–å›¾åƒæ–‡ä»¶
        image_data = await file.read()
        
        # ç”Ÿæˆç¼“å­˜é”®
        cache_key = f"{vehicle_model}_{water_model}_{hash(image_data)}"
        
        # æ£€æŸ¥ç¼“å­˜
        with cache_lock:
            if cache_key in request_cache:
                cached_result = request_cache[cache_key]
                print(f"ä½¿ç”¨ç¼“å­˜ç»“æœï¼Œç¼“å­˜é”®: {cache_key[:20]}...")
                return cached_result
        
        # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡ŒCPUå¯†é›†å‹ä»»åŠ¡
        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(
            executor, 
            perform_analysis_optimized, 
            image_data, 
            vehicle_model, 
            water_model
        )
        
        # æ·»åŠ åå°ä»»åŠ¡è¿›è¡Œå†…å­˜æ¸…ç†
        background_tasks.add_task(cleanup_memory)
        
        # ç¼“å­˜ç»“æœï¼ˆé™åˆ¶ç¼“å­˜å¤§å°ï¼‰
        with cache_lock:
            if len(request_cache) > 50:  # é™åˆ¶ç¼“å­˜æ¡ç›®æ•°
                # åˆ é™¤æœ€æ—§çš„ç¼“å­˜é¡¹
                oldest_key = next(iter(request_cache))
                del request_cache[oldest_key]
            request_cache[cache_key] = result
        
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"åˆ†æå¤±è´¥: {str(e)}"
        )


def perform_analysis_optimized(
    image_data: bytes, 
    vehicle_model: str, 
    water_model: str
) -> AnalysisResponse:
    """
    ä¼˜åŒ–çš„å›¾åƒåˆ†æå‡½æ•°
    
    Args:
        image_data: å›¾åƒå­—èŠ‚æ•°æ®
        vehicle_model: è½¦è¾†æ£€æµ‹æ¨¡å‹åç§°
        water_model: æ°´é¢åˆ†å‰²æ¨¡å‹åç§°
        
    Returns:
        AnalysisResponse: åˆ†æå“åº”
    """
    start_time = time.time()
    
    try:
        # ä½¿ç”¨åˆ†æé”é˜²æ­¢å¹¶å‘å†²çª
        with analysis_lock:
            # å¿«é€ŸåŠ è½½å›¾åƒ
            image = load_image_from_bytes_fast(image_data)
            
            # è®¾ç½®æ¨¡å‹
            success = model_manager.set_active_models(vehicle_model, water_model)
            if not success:
                raise ValueError(f"æ— æ³•è®¾ç½®æ¨¡å‹: {vehicle_model}, {water_model}")
            
            # æ‰§è¡Œåˆ†æ
            analysis_result = perform_analysis_fast(image)
            
            # ç”Ÿæˆç»“æœå›¾åƒ
            result_image = viz_engine.create_result_image_fast(image, analysis_result)
            result_image_base64 = image_to_base64_fast(result_image)
            
            # è®¡ç®—å¤„ç†æ—¶é—´
            processing_time = time.time() - start_time
            
            # æ„å»ºè½¦è¾†ç»“æœ
            vehicles = []
            for vehicle in analysis_result.vehicles:
                vehicles.append(VehicleResult(
                    id=vehicle.vehicle_id,
                    bbox=[
                        vehicle.detection.bbox.x1,
                        vehicle.detection.bbox.y1,
                        vehicle.detection.bbox.x2,
                        vehicle.detection.bbox.y2
                    ],
                    confidence=vehicle.detection.bbox.confidence,
                    flood_level=vehicle.flood_level.value,
                    overlap_ratio=vehicle.overlap_ratio
                ))
            
            # æ„å»ºç»Ÿè®¡ä¿¡æ¯
            stats = analysis_result.statistics
            statistics = {
                "total_vehicles": stats.total_vehicles,
                "light_flood_count": stats.light_flood_count,
                "moderate_flood_count": stats.moderate_flood_count,
                "severe_flood_count": stats.severe_flood_count,
                "water_coverage_percentage": stats.water_coverage_percentage,
                "processing_time": processing_time
            }
            
            return AnalysisResponse(
                success=True,
                message="åˆ†æå®Œæˆ",
                vehicles=vehicles,
                statistics=statistics,
                processing_time=processing_time,
                result_image_base64=result_image_base64,
                water_coverage_percentage=stats.water_coverage_percentage
            )
    
    except Exception as e:
        raise ValueError(f"åˆ†æå¤±è´¥: {str(e)}")

def load_image_from_bytes_fast(image_data: bytes) -> np.ndarray:
    """å¿«é€Ÿä»å­—èŠ‚æ•°æ®åŠ è½½å›¾åƒ"""
    try:
        # ä½¿ç”¨æ›´å¿«çš„å›¾åƒåŠ è½½æ–¹æ³•
        nparr = np.frombuffer(image_data, np.uint8)
        image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        
        if image is None:
            # å›é€€åˆ°PILæ–¹æ³•
            pil_image = Image.open(io.BytesIO(image_data))
            if pil_image.mode != 'RGB':
                pil_image = pil_image.convert('RGB')
            image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
        
        return image
        
    except Exception as e:
        raise ValueError(f"å›¾åƒåŠ è½½å¤±è´¥: {str(e)}")

def load_image_from_bytes(image_data: bytes) -> np.ndarray:
    """ä»å­—èŠ‚æ•°æ®åŠ è½½å›¾åƒ - å…¼å®¹æ€§æ–¹æ³•"""
    return load_image_from_bytes_fast(image_data)


def perform_analysis_fast(image: np.ndarray) -> AnalysisResult:
    """æ‰§è¡Œå¿«é€Ÿå›¾åƒåˆ†æ"""
    try:
        # è½¦è¾†æ£€æµ‹
        vehicles = model_manager.predict_vehicles(image)
        
        # æ°´é¢åˆ†å‰²
        water_mask = model_manager.predict_water(image)
        
        # æ·¹æ²¡åˆ†æ - ä½¿ç”¨æ‰¹é‡ä¼˜åŒ–ç‰ˆæœ¬
        analysis_result = flood_analyzer.analyze_scene_batch(vehicles, water_mask)
        
        return analysis_result
        
    except Exception as e:
        raise InferenceError("å›¾åƒåˆ†æ", str(e))

def perform_analysis(image: np.ndarray) -> AnalysisResult:
    """æ‰§è¡Œå›¾åƒåˆ†æ - å…¼å®¹æ€§æ–¹æ³•"""
    return perform_analysis_fast(image)


def image_to_base64_fast(image: np.ndarray) -> str:
    """å¿«é€Ÿå°†å›¾åƒè½¬æ¢ä¸ºbase64å­—ç¬¦ä¸²"""
    try:
        # ä½¿ç”¨OpenCVç›´æ¥ç¼–ç ï¼Œé¿å…PILè½¬æ¢
        success, buffer = cv2.imencode('.jpg', image, [cv2.IMWRITE_JPEG_QUALITY, 85])
        
        if not success:
            raise ValueError("å›¾åƒç¼–ç å¤±è´¥")
        
        # ç¼–ç ä¸ºbase64
        image_base64 = base64.b64encode(buffer).decode('utf-8')
        
        return image_base64
        
    except Exception as e:
        raise ValueError(f"å›¾åƒç¼–ç å¤±è´¥: {str(e)}")

def image_to_base64(image: np.ndarray) -> str:
    """å°†å›¾åƒè½¬æ¢ä¸ºbase64å­—ç¬¦ä¸² - å…¼å®¹æ€§æ–¹æ³•"""
    return image_to_base64_fast(image)


# é”™è¯¯å¤„ç†
@app.exception_handler(FloodDetectionError)
async def flood_detection_error_handler(request, exc: FloodDetectionError):
    """å¤„ç†è‡ªå®šä¹‰å¼‚å¸¸"""
    return JSONResponse(
        status_code=500,
        content=ErrorResponse(
            success=False,
            error=exc.message,
            error_code=exc.error_code or "UNKNOWN_ERROR"
        ).dict()
    )


@app.exception_handler(HTTPException)
async def http_exception_handler(request, exc: HTTPException):
    """å¤„ç†HTTPå¼‚å¸¸"""
    return JSONResponse(
        status_code=exc.status_code,
        content=ErrorResponse(
            success=False,
            error=exc.detail,
            error_code=f"HTTP_{exc.status_code}"
        ).dict()
    )


def cleanup_memory():
    """åå°å†…å­˜æ¸…ç†ä»»åŠ¡"""
    try:
        # æ¸…ç†æ¨¡å‹ç®¡ç†å™¨ç¼“å­˜
        if model_manager:
            model_manager.optimize_memory()
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()
        
        print("åå°å†…å­˜æ¸…ç†å®Œæˆ")
    except Exception as e:
        print(f"å†…å­˜æ¸…ç†å¤±è´¥: {e}")

@app.get("/api/performance")
async def get_performance_info():
    """è·å–æ€§èƒ½ä¿¡æ¯"""
    try:
        performance_info = {
            "models_loaded": models_loaded,
            "cache_size": len(request_cache),
            "executor_threads": executor._max_workers
        }
        
        if model_manager:
            performance_info.update(model_manager.get_memory_usage())
        
        return performance_info
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"è·å–æ€§èƒ½ä¿¡æ¯å¤±è´¥: {str(e)}"
        )

@app.post("/api/optimize")
async def optimize_performance():
    """æ‰‹åŠ¨è§¦å‘æ€§èƒ½ä¼˜åŒ–"""
    try:
        # æ¸…ç†ç¼“å­˜
        with cache_lock:
            request_cache.clear()
        
        # ä¼˜åŒ–æ¨¡å‹å†…å­˜
        if model_manager:
            model_manager.optimize_memory()
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()
        
        return {
            "success": True,
            "message": "æ€§èƒ½ä¼˜åŒ–å®Œæˆ",
            "timestamp": time.time()
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"æ€§èƒ½ä¼˜åŒ–å¤±è´¥: {str(e)}"
        )

if __name__ == "__main__":
    import uvicorn
    
    # å¼€å‘ç¯å¢ƒè¿è¡Œ - æ€§èƒ½ä¼˜åŒ–é…ç½®
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info",
        workers=1,  # å•è¿›ç¨‹ä»¥é¿å…æ¨¡å‹é‡å¤åŠ è½½
        loop="asyncio",
        access_log=False  # ç¦ç”¨è®¿é—®æ—¥å¿—ä»¥æé«˜æ€§èƒ½
    )
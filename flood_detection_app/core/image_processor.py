"""
å›¾åƒå¤„ç†å™¨
Image Processor for loading, preprocessing and saving images
"""

import os
import cv2
import numpy as np
import torch
from PIL import Image, ImageOps
from typing import Tuple, Optional, Union
from pathlib import Path
from functools import lru_cache
import threading
from concurrent.futures import ThreadPoolExecutor
import time

from .exceptions import ImageProcessingError, FileOperationError, ValidationError
from .config import config_manager


class ImageProcessor:
    """å›¾åƒå¤„ç†å™¨ç±» - æ€§èƒ½ä¼˜åŒ–ç‰ˆæœ¬"""
    
    # ç±»çº§åˆ«çš„çº¿ç¨‹æ± ï¼Œç”¨äºå¹¶è¡Œå¤„ç†
    _thread_pool = ThreadPoolExecutor(max_workers=2)
    _processing_lock = threading.Lock()
    
    @staticmethod
    @lru_cache(maxsize=16)
    def _get_image_info_cached(file_path: str, file_size: int) -> dict:
        """ç¼“å­˜å›¾åƒä¿¡æ¯ä»¥é¿å…é‡å¤è¯»å–"""
        return {
            'path': file_path,
            'size': file_size,
            'cached_at': time.time()
        }
    
    @staticmethod
    def load_image(file_path: str) -> np.ndarray:
        """
        åŠ è½½å›¾åƒæ–‡ä»¶
        
        Args:
            file_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            
        Returns:
            np.ndarray: BGRæ ¼å¼çš„å›¾åƒæ•°ç»„
            
        Raises:
            ImageProcessingError: å›¾åƒåŠ è½½å¤±è´¥
            ValidationError: æ–‡ä»¶æ ¼å¼ä¸æ”¯æŒ
        """
        if not os.path.exists(file_path):
            raise FileOperationError("è¯»å–", file_path, "æ–‡ä»¶ä¸å­˜åœ¨")
        
        # éªŒè¯æ–‡ä»¶æ ¼å¼
        if not config_manager.validate_image_format(file_path):
            raise ValidationError("å›¾åƒæ ¼å¼", file_path, "ä¸æ”¯æŒçš„å›¾åƒæ ¼å¼")
        
        try:
            # ä¼˜åŒ–çš„å›¾åƒåŠ è½½ç­–ç•¥
            # é¦–å…ˆå°è¯•ä½¿ç”¨OpenCVï¼ˆé€šå¸¸æ›´å¿«ï¼‰
            image = cv2.imread(file_path, cv2.IMREAD_COLOR)
            
            if image is None:
                # å›é€€åˆ°PILï¼ˆæ”¯æŒæ›´å¤šæ ¼å¼ï¼‰
                try:
                    with Image.open(file_path) as pil_image:
                        # è½¬æ¢ä¸ºRGBç„¶åè½¬ä¸ºBGRï¼ˆOpenCVæ ¼å¼ï¼‰
                        if pil_image.mode != 'RGB':
                            pil_image = pil_image.convert('RGB')
                        image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
                except Exception as e:
                    raise ImageProcessingError("å›¾åƒåŠ è½½", file_path, f"PILåŠ è½½å¤±è´¥: {str(e)}")
            
            # ä¼˜åŒ–çš„å°ºå¯¸æ£€æŸ¥å’Œç¼©æ”¾
            max_size = config_manager.config.max_image_size
            h, w = image.shape[:2]
            
            if h > max_size[1] or w > max_size[0]:
                print(f"è­¦å‘Š: å›¾åƒå°ºå¯¸ {(h, w)} è¶…è¿‡æœ€å¤§é™åˆ¶ {max_size}ï¼Œå°†è¿›è¡Œç¼©æ”¾")
                # ä½¿ç”¨æ›´å¿«çš„ç¼©æ”¾æ–¹æ³•
                image = ImageProcessor.resize_with_aspect_ratio_fast(image, max_size)
            
            return image
            
        except Exception as e:
            if isinstance(e, (ImageProcessingError, ValidationError, FileOperationError)):
                raise
            raise ImageProcessingError("å›¾åƒåŠ è½½", file_path, str(e))
    
    @staticmethod
    def save_image(image: np.ndarray, file_path: str, quality: int = 95) -> bool:
        """
        ä¿å­˜å›¾åƒåˆ°æ–‡ä»¶
        
        Args:
            image: BGRæ ¼å¼çš„å›¾åƒæ•°ç»„
            file_path: ä¿å­˜è·¯å¾„
            quality: JPEGè´¨é‡ (1-100)
            
        Returns:
            bool: ä¿å­˜æ˜¯å¦æˆåŠŸ
            
        Raises:
            ImageProcessingError: å›¾åƒä¿å­˜å¤±è´¥
        """
        try:
            # åˆ›å»ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            dir_path = os.path.dirname(file_path)
            if dir_path:  # åªæœ‰å½“ç›®å½•è·¯å¾„ä¸ä¸ºç©ºæ—¶æ‰åˆ›å»º
                os.makedirs(dir_path, exist_ok=True)
            
            # æ ¹æ®æ–‡ä»¶æ‰©å±•åè®¾ç½®ä¿å­˜å‚æ•°
            _, ext = os.path.splitext(file_path.lower())
            
            if ext in ['.jpg', '.jpeg']:
                # JPEGæ ¼å¼
                success = cv2.imwrite(file_path, image, [cv2.IMWRITE_JPEG_QUALITY, quality])
            elif ext == '.png':
                # PNGæ ¼å¼
                success = cv2.imwrite(file_path, image, [cv2.IMWRITE_PNG_COMPRESSION, 9])
            else:
                # å…¶ä»–æ ¼å¼
                success = cv2.imwrite(file_path, image)
            
            if not success:
                raise ImageProcessingError("å›¾åƒä¿å­˜", file_path, "OpenCVä¿å­˜å¤±è´¥")
            
            return True
            
        except Exception as e:
            if isinstance(e, ImageProcessingError):
                raise
            raise ImageProcessingError("å›¾åƒä¿å­˜", file_path, str(e))
    
    @staticmethod
    def resize_with_aspect_ratio_fast(
        image: np.ndarray, 
        target_size: Tuple[int, int]
    ) -> np.ndarray:
        """
        å¿«é€Ÿä¿æŒå®½é«˜æ¯”çš„å›¾åƒç¼©æ”¾
        
        Args:
            image: è¾“å…¥å›¾åƒ
            target_size: ç›®æ ‡å°ºå¯¸ (width, height)
            
        Returns:
            np.ndarray: ç¼©æ”¾åçš„å›¾åƒ
        """
        try:
            h, w = image.shape[:2]
            target_w, target_h = target_size
            
            # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
            scale = min(target_w / w, target_h / h)
            
            # å¦‚æœä¸éœ€è¦ç¼©æ”¾ï¼Œç›´æ¥è¿”å›
            if scale >= 1.0:
                return image
            
            # è®¡ç®—æ–°å°ºå¯¸
            new_w = int(w * scale)
            new_h = int(h * scale)
            
            # ä½¿ç”¨æ›´å¿«çš„æ’å€¼æ–¹æ³•è¿›è¡Œç¼©æ”¾
            if scale < 0.5:
                # å¤§å¹…ç¼©æ”¾æ—¶ä½¿ç”¨INTER_AREA
                interpolation = cv2.INTER_AREA
            else:
                # å°å¹…ç¼©æ”¾æ—¶ä½¿ç”¨INTER_LINEAR
                interpolation = cv2.INTER_LINEAR
            
            resized = cv2.resize(image, (new_w, new_h), interpolation=interpolation)
            
            return resized
            
        except Exception as e:
            raise ImageProcessingError("å›¾åƒç¼©æ”¾", None, str(e))
    
    @staticmethod
    def resize_with_aspect_ratio(
        image: np.ndarray, 
        target_size: Tuple[int, int], 
        interpolation: int = cv2.INTER_LINEAR
    ) -> np.ndarray:
        """
        ä¿æŒå®½é«˜æ¯”çš„å›¾åƒç¼©æ”¾
        
        Args:
            image: è¾“å…¥å›¾åƒ
            target_size: ç›®æ ‡å°ºå¯¸ (width, height)
            interpolation: æ’å€¼æ–¹æ³•
            
        Returns:
            np.ndarray: ç¼©æ”¾åçš„å›¾åƒ
        """
        # å…¼å®¹æ€§æ–¹æ³•ï¼Œè°ƒç”¨å¿«é€Ÿç‰ˆæœ¬
        return ImageProcessor.resize_with_aspect_ratio_fast(image, target_size)
    
    @staticmethod
    def preprocess_for_model_fast(
        image: np.ndarray, 
        model_type: str, 
        input_size: Tuple[int, int] = (640, 640)
    ) -> torch.Tensor:
        """
        ä¸ºæ¨¡å‹æ¨ç†å¿«é€Ÿé¢„å¤„ç†å›¾åƒ
        
        Args:
            image: BGRæ ¼å¼çš„è¾“å…¥å›¾åƒ
            model_type: æ¨¡å‹ç±»å‹ ('yolo', 'deeplabv3', 'rtdetr')
            input_size: æ¨¡å‹è¾“å…¥å°ºå¯¸ (width, height)
            
        Returns:
            torch.Tensor: é¢„å¤„ç†åçš„å¼ é‡
        """
        try:
            # è½¬æ¢ä¸ºRGBæ ¼å¼
            rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            if model_type.lower() in ['yolo', 'yolov11', 'rtdetr']:
                # ğŸ”¥ YOLO/RT-DETRé¢„å¤„ç† - ä½¿ç”¨ä¸Ultralyticsè®­ç»ƒæ—¶ä¸€è‡´çš„æ–¹æ³•
                # 1. è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼ˆä¿æŒå®½é«˜æ¯”ï¼‰
                h, w = rgb_image.shape[:2]
                target_w, target_h = input_size
                scale = min(target_w / w, target_h / h)
                
                # 2. ç¼©æ”¾å›¾åƒ
                new_w, new_h = int(w * scale), int(h * scale)
                resized = cv2.resize(rgb_image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
                
                # 3. åˆ›å»ºå¡«å……å›¾åƒï¼ˆä½¿ç”¨114ä½œä¸ºå¡«å……å€¼ï¼Œä¸Ultralyticsä¸€è‡´ï¼‰
                padded = np.full((target_h, target_w, 3), 114, dtype=np.uint8)
                y_offset = (target_h - new_h) // 2
                x_offset = (target_w - new_w) // 2
                padded[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized
                
                # 4. å½’ä¸€åŒ–
                normalized = padded.astype(np.float32) / 255.0
                
            elif model_type.lower() in ['deeplabv3', 'deeplab']:
                # DeepLabV3é¢„å¤„ç† - ç›´æ¥ç¼©æ”¾ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
                resized = cv2.resize(rgb_image, input_size, interpolation=cv2.INTER_LINEAR)
                
                # åªåšç®€å•å½’ä¸€åŒ–ï¼ˆä¸è®­ç»ƒæ—¶çš„Albumentationsä¸€è‡´ï¼‰
                normalized = resized.astype(np.float32) / 255.0
                
            else:
                # é€šç”¨é¢„å¤„ç† - ç›´æ¥ç¼©æ”¾
                resized = cv2.resize(rgb_image, input_size, interpolation=cv2.INTER_LINEAR)
                normalized = resized.astype(np.float32) / 255.0
            
            # è½¬æ¢ä¸ºå¼ é‡å¹¶è°ƒæ•´ç»´åº¦ (H, W, C) -> (1, C, H, W)
            tensor = torch.from_numpy(normalized).permute(2, 0, 1).unsqueeze(0)
            
            return tensor
            
        except Exception as e:
            raise ImageProcessingError("æ¨¡å‹é¢„å¤„ç†", None, str(e))
    
    @staticmethod
    def preprocess_for_model(
        image: np.ndarray, 
        model_type: str, 
        input_size: Tuple[int, int] = (640, 640)
    ) -> torch.Tensor:
        """
        ä¸ºæ¨¡å‹æ¨ç†é¢„å¤„ç†å›¾åƒ
        
        Args:
            image: BGRæ ¼å¼çš„è¾“å…¥å›¾åƒ
            model_type: æ¨¡å‹ç±»å‹ ('yolo', 'deeplabv3', 'rtdetr')
            input_size: æ¨¡å‹è¾“å…¥å°ºå¯¸ (width, height)
            
        Returns:
            torch.Tensor: é¢„å¤„ç†åçš„å¼ é‡
        """
        # å…¼å®¹æ€§æ–¹æ³•ï¼Œè°ƒç”¨å¿«é€Ÿç‰ˆæœ¬
        return ImageProcessor.preprocess_for_model_fast(image, model_type, input_size)
    
    @staticmethod
    def postprocess_mask(
        mask: np.ndarray, 
        original_size: Tuple[int, int],
        threshold: float = 0.5
    ) -> np.ndarray:
        """
        åå¤„ç†åˆ†å‰²æ©ç 
        
        Args:
            mask: æ¨¡å‹è¾“å‡ºçš„æ©ç 
            original_size: åŸå§‹å›¾åƒå°ºå¯¸ (width, height)
            threshold: äºŒå€¼åŒ–é˜ˆå€¼
            
        Returns:
            np.ndarray: å¤„ç†åçš„äºŒå€¼æ©ç 
        """
        try:
            # ç¡®ä¿æ©ç æ˜¯2Dçš„
            if len(mask.shape) > 2:
                mask = mask.squeeze()
            
            # äºŒå€¼åŒ–
            binary_mask = (mask > threshold).astype(np.uint8)
            
            # è°ƒæ•´åˆ°åŸå§‹å°ºå¯¸
            if binary_mask.shape != original_size[::-1]:  # OpenCVä½¿ç”¨ (height, width)
                binary_mask = cv2.resize(
                    binary_mask, 
                    original_size, 
                    interpolation=cv2.INTER_NEAREST
                )
            
            return binary_mask
            
        except Exception as e:
            raise ImageProcessingError("æ©ç åå¤„ç†", None, str(e))
    
    @staticmethod
    def create_overlay(
        image: np.ndarray, 
        mask: np.ndarray, 
        color: Tuple[int, int, int] = (0, 255, 255),
        alpha: float = 0.3
    ) -> np.ndarray:
        """
        åˆ›å»ºæ©ç å åŠ å›¾åƒ
        
        Args:
            image: åŸå§‹å›¾åƒ (BGR)
            mask: äºŒå€¼æ©ç 
            color: å åŠ é¢œè‰² (BGR)
            alpha: é€æ˜åº¦
            
        Returns:
            np.ndarray: å åŠ åçš„å›¾åƒ
        """
        try:
            overlay = image.copy()
            
            # ç¡®ä¿æ©ç æ˜¯äºŒå€¼çš„
            if mask.dtype != np.uint8:
                mask = mask.astype(np.uint8)
            
            # åˆ›å»ºå½©è‰²æ©ç 
            colored_mask = np.zeros_like(image)
            colored_mask[mask > 0] = color
            
            # å åŠ 
            overlay = cv2.addWeighted(overlay, 1 - alpha, colored_mask, alpha, 0)
            
            return overlay
            
        except Exception as e:
            raise ImageProcessingError("æ©ç å åŠ ", None, str(e))
    
    @staticmethod
    def validate_image(image: np.ndarray) -> bool:
        """
        éªŒè¯å›¾åƒæ•°æ®çš„æœ‰æ•ˆæ€§
        
        Args:
            image: å›¾åƒæ•°ç»„
            
        Returns:
            bool: æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            if image is None:
                return False
            
            if not isinstance(image, np.ndarray):
                return False
            
            if len(image.shape) not in [2, 3]:
                return False
            
            if len(image.shape) == 3 and image.shape[2] not in [1, 3, 4]:
                return False
            
            if image.size == 0:
                return False
            
            return True
            
        except:
            return False
    
    @staticmethod
    def get_image_info(image: np.ndarray) -> dict:
        """
        è·å–å›¾åƒä¿¡æ¯
        
        Args:
            image: å›¾åƒæ•°ç»„
            
        Returns:
            dict: å›¾åƒä¿¡æ¯
        """
        try:
            if not ImageProcessor.validate_image(image):
                return {"valid": False}
            
            info = {
                "valid": True,
                "shape": image.shape,
                "dtype": str(image.dtype),
                "size": image.size,
                "channels": image.shape[2] if len(image.shape) == 3 else 1,
                "width": image.shape[1],
                "height": image.shape[0]
            }
            
            return info
            
        except Exception as e:
            return {"valid": False, "error": str(e)}